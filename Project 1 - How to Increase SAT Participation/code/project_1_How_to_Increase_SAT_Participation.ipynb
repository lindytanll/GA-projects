{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an employee of the College Board and part of a team to monitor statewide participation, this project aims to:\n",
    "- Explore trends in SAT, as well as ACT, participation rates over the years from 2017-2019; and\n",
    "- To identify and provide recommendations on the states which we can focus our resources to improve SAT participation rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Audience: College Board (i.e. the organization that administers the SAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAT and ACT are standardized tests that many colleges and universities in the United States require for their admissions process. This score is used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university.\n",
    "\n",
    "The SAT has two sections of the test: Evidence-Based Reading and Writing and Math ([*source*](https://www.princetonreview.com/college/sat-sections)). The ACT has 4 sections: English, Mathematics, Reading, and Science, with an additional optional writing section ([*source*](https://www.act.org/content/act/en/products-and-services/the-act/scores/understanding-your-scores.html)). For SAT, each section is scored on a scale of 200-800, with overall total score ranging between 400-1,600 (sum of sections). For ACT, each section has a scaled score of 1-36, with the overall composite score ranging between 1-36 (average of sections). More details can be found:\n",
    "* [SAT](https://collegereadiness.collegeboard.org/sat)\n",
    "* [ACT](https://www.act.org/content/act/en.html)\n",
    "\n",
    "Standardized tests have long been a controversial topic for students, administrators, and legislators. Since the 1940's, an increasing number of colleges have been using scores from sudents' performances on tests like the SAT and the ACT as a measure for college readiness and aptitude ([*source*](https://www.minotdailynews.com/news/local-news/2017/04/a-brief-history-of-the-sat-and-act/)). Supporters of these tests argue that these scores can be used as an objective measure to determine college admittance. Opponents of these tests claim that these tests are not accurate measures of students potential or ability and serve as an inequitable barrier to entry. Lately, more and more schools are opting to drop the SAT/ACT requirement for their Fall 2021 applications ([*read more about this here*](https://www.cnn.com/2020/04/14/us/coronavirus-colleges-sat-act-test-trnd/index.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some states, the State Boards of Education paid for and mandate students to take state-administered SATs and ACTs in their public school juniors. The results are used to determine statewide scholastic achievement. Students can use scores from their state-administered test for college admissions, or can take the SAT or ACT again if they are not satisfy with the score.([*source*](https://testive.com/state-sat-act/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 10 datasets included in the [`data`](./data/) folder for this project. You are required to pick **at least two** of these to complete your analysis. Feel free to use more than two if you would like, or add other relevant datasets you find online.\n",
    "\n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Scores by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Scores by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Scores by State\n",
    "* [`act_2019_ca.csv`](./data/act_2019_ca.csv): 2019 ACT Scores in California by School\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Scores by State\n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Scores by State\n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Scores by State\n",
    "* [`sat_2019_by_intended_college_major.csv`](./data/sat_2019_by_intended_college_major.csv): 2019 SAT Scores by Intended College Major\n",
    "* [`sat_2019_ca.csv`](./data/sat_2019_ca.csv): 2019 SAT Scores in California by School\n",
    "* [`sat_act_by_college.csv`](./data/sat_act_by_college.csv): Ranges of Accepted ACT & SAT Student Scores by Colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following datasets are used for the study:\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Participation Rate and Scores (EBRW, Math, Total) by State. \n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Participation Rate and Scores (EBRW, Math, Total) by State. \n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Participation Rate and Scores (EBRW, Math, Total) by State. \n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Participation Rate and Scores (English, Math, Reading, Science, Composite)  by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Participation Rate and Scores (Composite) by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Participation Rate and Scores (Composite) by State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The preference for one standardized test over another tends to be largely geographical in nature. For that reason, in states with high SAT participation, ACT participation tends to be much lower, and the same is true vice versa ([*source*](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)).\n",
    "\n",
    "2) Some states have state-administered SATs and ACTs which are required for public school juniors, held in April and paid-for by the respective State Boards of Education. For example, Illinois opted to switch to the state-administered SAT in 2016-17 ([*source*](https://testive.com/state-sat-act/)). This may affect the participation rate.\n",
    "\n",
    "States that require the ACT:\n",
    "\n",
    "* Alabama\n",
    "* Hawaii\n",
    "* Idaho\n",
    "* Kentucky\n",
    "* Louisiana\n",
    "* Mississippi\n",
    "* Missouri\n",
    "* Montana\n",
    "* Nebraska\n",
    "* Nevada\n",
    "* North Carolina\n",
    "* North Dakota\n",
    "* Ohio\n",
    "* South Carolina\n",
    "* Tennessee\n",
    "* Utah\n",
    "* Wisconsin\n",
    "* Wyoming\n",
    "\n",
    "States that require the SAT:\n",
    "\n",
    "* Colorado\n",
    "* Connecticut\n",
    "* Delaware\n",
    "* District of Columbia\n",
    "* Idaho\n",
    "* Illinois\n",
    "* Maine\n",
    "* Michigan\n",
    "* New Hampshire\n",
    "* Ohio\n",
    "* Tennessee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def mean(values):\n",
    "    \"\"\" Input list of integers or floats and output is the average\"\"\"\n",
    "    return sum(values)/len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = list(range(1,6))\n",
    "print(score)\n",
    "mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "print(score2)\n",
    "mean(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def standard_deviation(values):\n",
    "    \"\"\" Input list of integers or floats and output is the standard deviation\"\"\"\n",
    "    sse = 0\n",
    "    for num in values:\n",
    "        error = (num-mean(values))**2\n",
    "        sse += error\n",
    "    return ((1 / len(values)) * sse) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_deviation(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.707825127659933"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_deviation(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def num_process(string):\n",
    "    if \"%\" in string:\n",
    "        return float(string.replace(\"%\",\"\"))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.305\n"
     ]
    }
   ],
   "source": [
    "print(num_process('50%'))\n",
    "print(num_process('30.5%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"C:/Users/xiang/Documents/GA-projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/sat_2017.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13808/367464902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Code:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msat2017\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/sat_2017.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msat2017\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msat2017\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/sat_2017.csv'"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "sat2017 = pd.read_csv('../data/sat_2017.csv')\n",
    "print(sat2017.head())\n",
    "print(sat2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2018 = pd.read_csv('data/sat_2018.csv')\n",
    "print(sat2018.head())\n",
    "print(sat2018.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2019 = pd.read_csv('data/sat_2019.csv')\n",
    "print(sat2019.head())\n",
    "print(sat2019.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine further which are the two additional rows in sat2019.\n",
    "# There are 2 new territories - Puerto Rico and Virgin Islands - in sat2019\n",
    "df = pd.merge(sat2017['State'], sat2019['State'], how='outer', indicator='Exist')\n",
    "df = df.loc[df['Exist'] != 'both']\n",
    "print(df)\n",
    "sat2019.loc[(sat2019['State'] == \"Puerto Rico\") | (sat2019['State'] == \"Virgin Islands\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will drop them as participation info is not available for our study\n",
    "sat2019 = sat2019[(sat2019['State'] != 'Puerto Rico') & (sat2019['State'] != 'Virgin Islands')]\n",
    "sat2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the headers of sat2019 to align with that for sat2017 and sat2018\n",
    "sat2019.rename(columns={\n",
    "    'EBRW': 'Evidence-Based Reading and Writing',\n",
    "    'Participation Rate': 'Participation'\n",
    "}, inplace=True)\n",
    "sat2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for year for all 3 sat dataframes\n",
    "sat2017[\"year\"] = \"2017-01-01\"\n",
    "sat2017[\"year\"] = pd.to_datetime(sat2017[\"year\"])\n",
    "sat2018[\"year\"] = \"2018-01-01\"\n",
    "sat2018[\"year\"] = pd.to_datetime(sat2018[\"year\"])\n",
    "sat2019[\"year\"] = \"2019-01-01\"\n",
    "sat2019[\"year\"] = pd.to_datetime(sat2019[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the 3 sat dataframes\n",
    "sat = pd.concat([sat2017, sat2018, sat2019], ignore_index=True)\n",
    "sat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SAT, the score range for each section is 200 to 800.\n",
    "# The score range for the entire test is 400 to 1,600.\n",
    "# From the desctibe() output, there is a min score of 52 for math, which could be an entry error.\n",
    "sat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further examination of the row with math score of 52, confirms that it is an entry error.\n",
    "# Total score is 1060 and reading/writing score is 536, so math score should be 524.\n",
    "sat[sat['Math'] == 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace math score of 52 with 524.\n",
    "# Scores in the desctibe() output are now within the corrent range.\n",
    "sat.loc[20, 'Math'] = 524\n",
    "sat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat['sat_participation'] = sat['Participation'].map(num_process)\n",
    "print(sat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"Participation\" columns\n",
    "sat = sat.drop('Participation', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act2017 = pd.read_csv('data/act_2017.csv')\n",
    "print(act2017.head())\n",
    "print(act2017.shape)\n",
    "act2018 = pd.read_csv('data/act_2018.csv')\n",
    "print(act2018.head())\n",
    "print(act2018.shape)\n",
    "act2019 = pd.read_csv('data/act_2019.csv')\n",
    "print(act2019.head())\n",
    "print(act2019.shape)\n",
    "\n",
    "# Add a column for year for all 3 act dataframes\n",
    "act2017[\"year\"] = \"2017-01-01\"\n",
    "act2017[\"year\"] = pd.to_datetime(act2017[\"year\"])\n",
    "act2018[\"year\"] = \"2018-01-01\"\n",
    "act2018[\"year\"] = pd.to_datetime(act2018[\"year\"])\n",
    "act2019[\"year\"] = \"2019-01-01\"\n",
    "act2019[\"year\"] = pd.to_datetime(act2019[\"year\"])\n",
    "\n",
    "# Append the 3 act dataframes\n",
    "act = pd.concat([act2017, act2018, act2019], ignore_index=True)\n",
    "print(act.head())\n",
    "print(act.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the row with State being \"National\" as it is the National Average ACT Score\n",
    "print(act[act['State'] == 'National'])\n",
    "act.drop([0,155], inplace = True)\n",
    "print(act.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an entry error for Wynoming's Composite score in act2017\n",
    "# Replace Composite score of 20.2x with 20.2 and convert Composite to float.\n",
    "print(act[act['Composite'] == \"20.2x\"])\n",
    "act.loc[51, 'Composite'] = 20.2\n",
    "act[\"Composite\"] = act[\"Composite\"].astype(float)\n",
    "act.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the scale for each section is 1-36, the min score for Science is 2.3,\n",
    "# while that of Composite is close to that of English, Math and Reading, suggesting that there could be an entry error\n",
    "print(act[act['Science'] == 2.3])\n",
    "\n",
    "# Based on Composite, which is average of all 4 sections, suggests that the score for Science is likely to be 23 instead of 2.3\n",
    "# Replace Science score with 23.\n",
    "act.loc[21, 'Science'] = 23\n",
    "act.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act['act_participation'] = act['Participation'].map(num_process)\n",
    "print(act.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"Participation\" columns\n",
    "act = act.drop('Participation', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all columns and make them lowercase\n",
    "sat.rename(columns={\n",
    "    'State': 'state',\n",
    "    'Evidence-Based Reading and Writing': 'sat_reading_writing',\n",
    "    'Math': 'sat_math',\n",
    "    'Total': 'sat_total'\n",
    "}, inplace=True)\n",
    "\n",
    "act.rename(columns={\n",
    "    'State': 'state',\n",
    "    'English': 'act_english',\n",
    "    'Math': 'act_math',\n",
    "    'Reading': 'act_reading',\n",
    "    'Science': 'act_science',\n",
    "    'Composite': 'act_composite'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#act['state'].str.replace('District of columbia', 'District of Columbia')\n",
    "act.loc[[60],'state'] = 'District of Columbia'\n",
    "print(act[(act['state']=='District of Columbia') | (act['state']=='District of columbia')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge sat and act datasets by State and Year\n",
    "sat_act = pd.merge(sat, act, on=[\"state\", \"year\"], how='outer', indicator='exist')\n",
    "print(sat_act.info())\n",
    "print(sat_act.loc[sat_act['exist'] != 'both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_act = sat_act[[\"state\", \"year\", \"sat_participation\", \"act_participation\", \"sat_reading_writing\", \"sat_math\", \"sat_total\", \"act_english\", \"act_math\", \"act_reading\", \"act_science\", \"act_composite\", \"exist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sat_act.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sat_act['sat_reading_writing'] = sat_act['sat_reading_writing'].astype(float)\n",
    "#sat_act['sat_math'] = sat_act['sat_math'].astype(float)\n",
    "#sat_act['sat_total'] = sat_act['sat_total'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting dataframe to csv\n",
    "sat_act.to_csv('sat_act.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|ACT/SAT|The states in US (a total of 51 states).|\n",
    "|year|datetime|ACT/SAT|The year which students took the ACT or SAT.|\n",
    "|sat_participation|float|SAT|Percentage of students in the state who took the SAT.|\n",
    "|act_participation|float|ACT|Percentage of students in the state who took the ACT.|\n",
    "|sat_reading_writing|int|SAT|Average score for Reading, Writing and Language in SAT for the state. Reading and Writing sections are combined to provide a final Evidence-Based Reading and Writing (EBRW) score on a scale of 200-800.|\n",
    "|sat_math|int|SAT|Average score for Math in SAT for the state. Math section is scored on a scale of 200-800.|\n",
    "|sat_total|int|SAT|Average overall score for SAT for the state . Overall score combines the Reading/Writing and Math section and has score range of 400-1600, with 1600 being a perfect score.|\n",
    "|act_english|float|ACT|Average scaled score for English section in ACT for the state. Scaled score range from 1-36, translated from raw score of 0-75.|\n",
    "|act_math|float|ACT|Average scaled score for Math section in ACT for the state. Scaled score range from 1-36, translated from raw score of 0-60.|\n",
    "|act_reading|float|ACT|Average scaled score for Reading section in ACT for the state. Scaled score range from 1-36, translated from raw score of 0-40.|\n",
    "|act_science|float|ACT|Average scaled score for Science section in ACT for the state. Scaled score range from 1-36, translated from raw score of 0-40.|\n",
    "|act_composite|float|ACT|Average overall score of the state for ACT. Overall composite score is a simple average of four area scores (i.e. English, Math, Reading and Science) with score range of 1-36.|\n",
    "|exist|object|-|Indicator on whether the data is present from SAT or ACT dataset.|\n",
    "\n",
    "\t\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to dictionary\n",
    "sat_act_dict = sat_act.to_dict('list')\n",
    "\n",
    "# Drop all missing values\n",
    "for key in sat_act_dict.keys():\n",
    "    if type(sat_act_dict[key][0]) == int or type(sat_act_dict[key][0]) == float:\n",
    "        sat_act_dict[key] = [float(num) for num in sat_act_dict[key]]\n",
    "        sat_act_dict[key] = [num for num in sat_act_dict[key] if math.isnan(num) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the standard_deviation function created in part 1 to each numeric column\n",
    "sd = {key:standard_deviation(list(value)) for key, value in sat_act_dict.items() if type(value[0])==int or type(value[0])==float}\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_act.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 1: States with high SAT participation are those which made SATs mandatory while those with low participation are those which made ACTs mandatory.\n",
    "\n",
    "* Connecticut, Delaware, and Michigan consistently had high participation rate for SAT from 2017 to 2019, while North Dakota consistenly had low participation rate. \n",
    "* On the other hand, Alabama, Arkansas, Wisconsin, Utah, Tennessee, Oklahoma, North Carolina, Nevada, Montana, Mississippi, Louisiana, Kentucky and Wyoming consistently had high participation rate for ACT while Maine consistenly had low participation rate.\n",
    "* Mississippi had one of the highest participation for ACT but lowest participation rate for SAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "sat_pariticipation_min_2017, sat_pariticipation_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'sat_participation'].agg([\"min\",\"max\"])\n",
    "sat_pariticipation_low_2017 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_min_2017), \"state\"]\n",
    "sat_pariticipation_high_2017 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2017), \"state\"]\n",
    "\n",
    "sat_pariticipation_min_2018, sat_pariticipation_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'sat_participation'].agg([\"min\",\"max\"])\n",
    "sat_pariticipation_low_2018 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_min_2018), \"state\"]\n",
    "sat_pariticipation_high_2018 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2018), \"state\"]\n",
    "\n",
    "sat_pariticipation_min_2019, sat_pariticipation_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'sat_participation'].agg([\"min\",\"max\"])\n",
    "sat_pariticipation_low_2019 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_min_2019), \"state\"]\n",
    "sat_pariticipation_high_2019 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2019), \"state\"]\n",
    "\n",
    "sat_act.loc[((sat_act['sat_participation'] == sat_pariticipation_min_2017) | ((sat_act['sat_participation'] == sat_pariticipation_max_2017))), [\"year\", \"state\", \"sat_participation\"]].sort_values('state', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_pariticipation_min_2017, act_pariticipation_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'act_participation'].agg([\"min\",\"max\"])\n",
    "act_pariticipation_low_2017 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['act_participation'] == act_pariticipation_min_2017), \"state\"]\n",
    "act_pariticipation_high_2017 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2017), \"state\"]\n",
    "\n",
    "act_pariticipation_min_2018, act_pariticipation_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'act_participation'].agg([\"min\",\"max\"])\n",
    "act_pariticipation_low_2018 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['act_participation'] == act_pariticipation_min_2018), \"state\"]\n",
    "act_pariticipation_high_2018 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2018), \"state\"]\n",
    "\n",
    "act_pariticipation_min_2019, act_pariticipation_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'act_participation'].agg([\"min\",\"max\"])\n",
    "act_pariticipation_low_2019 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['act_participation'] == act_pariticipation_min_2019), \"state\"]\n",
    "act_pariticipation_high_2019 = sat_act.loc[(sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2019), \"state\"]\n",
    "\n",
    "sat_act.loc[((sat_act['act_participation'] == act_pariticipation_min_2017) | ((sat_act['act_participation'] == act_pariticipation_max_2017))), [\"year\", \"state\", \"act_participation\"]].sort_values('act_participation', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([sat_pariticipation_high_2017, sat_pariticipation_high_2018, sat_pariticipation_high_2019], ignore_index=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([act_pariticipation_high_2017, act_pariticipation_high_2018, act_pariticipation_high_2019], ignore_index=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_state_w_full_participation = sat_act.loc[sat_act['state'].isin([\"Connecticut\", \"Delaware\", \"District of Columbia\", \"Michigan\", \"Colorado\", \"Idaho\", \"Florida\", \"Illinois\", \"Rhode Island\"])]['state'].unique()\n",
    "sat_state_w_lowest_participation = sat_act.loc[sat_act['state'].isin([\"North Dakota\", \"Mississippi\", \"Iowa\"])]['state'].unique()\n",
    "act_state_w_full_participation = sat_act.loc[sat_act['state'].isin([\"Alabama\", \"Arkansas\", \"Colorado\", \"Kentucky\", \"Louisiana\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nevada\", \"North Carolina\", \"Oklahoma\", \"South Carolina\", \"Tennessee\", \"Utah\", \"Wisconsin\", \"Wyoming\", \"Nebraska\", \"Ohio\"])][\"state\"].unique()\n",
    "act_state_w_lowest_participation = sat_act.loc[sat_act['state'].isin([\"Maine\"])][\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the size of the figure.\n",
    "plt.figure(figsize = (22, 15))\n",
    "\n",
    "# Taking a snapshot of 2017 distribution of participation rate for SAT\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title('Participation Rate by State for SAT 2017')\n",
    "ax1.barh(sat_act[sat_act['year'] == pd.to_datetime(\"2017-01-01\")].sort_values('state', ascending=False)['state'],\n",
    "         sat_act[sat_act['year'] == pd.to_datetime(\"2017-01-01\")].sort_values('state', ascending=False)['sat_participation'],\n",
    "         )\n",
    "\n",
    "# Taking a snapshot of 2017 distribution of participation rate for ACT\n",
    "ax2 = plt.subplot(1, 2, 2, sharex = ax1)\n",
    "ax2.set_title('Participation Rate by State for ACT 2017')\n",
    "ax2.barh(sat_act[sat_act['year'] == pd.to_datetime(\"2017-01-01\")].sort_values('state', ascending=False)['state'],\n",
    "         sat_act[sat_act['year'] == pd.to_datetime(\"2017-01-01\")].sort_values('state', ascending=False)['act_participation'],\n",
    "         );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 2: States with the highest score for SAT usually had low participation rate and those with lowest score for SAT had high participation rate. Similar trend for ACT.\n",
    "* Minnesota consistently had the highest mean total score from 2017 to 2019 for SAT, with low participation at about 3-4%, while District of Columbia had the lowest score for SAT, with participation of more than 90%. \n",
    "* Connecticut had the highest mean composite score for ACT, with low participation at about 22-26%, while Nevada had the lowest score, with participation of 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "sat_score_min_2017, sat_score_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'sat_total'].agg([\"min\",\"max\"])\n",
    "sat_score_min_2018, sat_score_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'sat_total'].agg([\"min\",\"max\"])\n",
    "sat_score_min_2019, sat_score_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'sat_total'].agg([\"min\",\"max\"])\n",
    "filter1 = (sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & ((sat_act['sat_total'] == sat_score_min_2017) | ((sat_act['sat_total'] == sat_score_max_2017)))\n",
    "filter2 = (sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & ((sat_act['sat_total'] == sat_score_min_2018) | ((sat_act['sat_total'] == sat_score_max_2018)))\n",
    "filter3 = (sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & ((sat_act['sat_total'] == sat_score_min_2019) | ((sat_act['sat_total'] == sat_score_max_2019)))\n",
    "sat_act.loc[filter1 | filter2 | filter3, [\"year\", \"state\", \"sat_total\", \"sat_participation\"]].sort_values(['sat_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_score_min_2017, act_score_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'act_composite'].agg([\"min\",\"max\"])\n",
    "act_score_min_2018, act_score_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'act_composite'].agg([\"min\",\"max\"])\n",
    "act_score_min_2019, act_score_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'act_composite'].agg([\"min\",\"max\"])\n",
    "filter1 = (sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & ((sat_act['act_composite'] == act_score_min_2017) | ((sat_act['act_composite'] == act_score_max_2017)))\n",
    "filter2 = (sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & ((sat_act['act_composite'] == act_score_min_2018) | ((sat_act['act_composite'] == act_score_max_2018)))\n",
    "filter3 = (sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & ((sat_act['act_composite'] == act_score_min_2019) | ((sat_act['act_composite'] == act_score_max_2019)))\n",
    "sat_act.loc[filter1 | filter2 | filter3, [\"year\", \"state\", \"act_composite\", \"act_participation\"]].sort_values(['act_composite'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 3: States with 100% participation for SAT typically continue to have high participation thereafter, due to it being made mandatory.\n",
    "* Colorado, Idaho, Illinois, and Rhode Island sustained close to 100% participation rate since 2018, with Michigan sustaining at 100% participation since 2017. \n",
    "* Similarly, states with 100% participation for ACT had high participation across years. Amongst 19 states, 16 states (except Colorado, South Carolina, and Missouri) had less than 10% year-to-year change in participation rate.\n",
    "* These are likely due to the tests being state-administered by the respective State Boards of Education in these states. For example, Illinois and Rhode Island mandated SAT in 2018, while Colorado changed mandate from ACT to SAT in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "# SAT\n",
    "sat_pariticipation_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'sat_participation'].max()\n",
    "sat_pariticipation_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'sat_participation'].max()\n",
    "sat_pariticipation_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'sat_participation'].max()\n",
    "filter1 = (sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2017)\n",
    "filter2 = (sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2018)\n",
    "filter3 = (sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['sat_participation'] == sat_pariticipation_max_2019)\n",
    "sat_act.loc[filter1 | filter2 | filter3, [\"state\"]].drop_duplicates(subset='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_act.loc[sat_act['state'].isin([\"Connecticut\", \"Delaware\", \"District of Columbia\", \"Michigan\", \"Colorado\", \"Idaho\", \"Florida\", \"Illinois\", \"Rhode Island\"])].sort_values([\"state\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "# ACT\n",
    "act_pariticipation_max_2017 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2017-01-01\"),'act_participation'].max()\n",
    "act_pariticipation_max_2018 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2018-01-01\"),'act_participation'].max()\n",
    "act_pariticipation_max_2019 = sat_act.loc[sat_act['year']== pd.to_datetime(\"2019-01-01\"),'act_participation'].max()\n",
    "filter1 = (sat_act['year'] == pd.to_datetime(\"2017-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2017)\n",
    "filter2 = (sat_act['year'] == pd.to_datetime(\"2018-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2018)\n",
    "filter3 = (sat_act['year'] == pd.to_datetime(\"2019-01-01\")) & (sat_act['act_participation'] == act_pariticipation_max_2019)\n",
    "sat_act.loc[filter1 | filter2 | filter3, [\"state\"]].drop_duplicates(subset='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_act.loc[sat_act['state'].isin([\"Alabama\", \"Arkansas\", \"Colorado\", \"Kentucky\", \"Louisiana\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nevada\", \"North Carolina\", \"Oklahoma\", \"South Carolina\", \"Tennessee\", \"Utah\", \"Wisconsin\", \"Wyoming\", \"Nebraska\", \"Ohio\"])].sort_values([\"state\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the size of the figure.\n",
    "plt.figure(figsize = (16, 9))\n",
    "\n",
    "# Create line plot of all stock volumes over 2012.\n",
    "for state in [\"Connecticut\", \"Delaware\", \"District of Columbia\", \"Michigan\", \"Colorado\", \"Idaho\", \"Florida\", \"Illinois\", \"Rhode Island\"]:\n",
    "                     \n",
    "    plt.plot(sat_act[(sat_act['state'] == state)]['year'],\n",
    "         sat_act[(sat_act['state'] == state)]['sat_participation'],\n",
    "         label = state,\n",
    "         marker = 'o')\n",
    "    \n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title(\"Participation Rate for States with 100% Participation for SAT\", fontsize = 24)\n",
    "plt.ylabel(\"Participation Rate\", fontsize = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establish the size of the figure.\n",
    "plt.figure(figsize = (16, 9))\n",
    "\n",
    "# Create line plot of all stock volumes over 2012.\n",
    "for state in [\"Alabama\", \"Arkansas\", \"Colorado\", \"Kentucky\", \"Louisiana\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nevada\", \"North Carolina\", \"Oklahoma\", \"South Carolina\", \"Tennessee\", \"Utah\", \"Wisconsin\", \"Wyoming\", \"Nebraska\", \"Ohio\"]:\n",
    "                     \n",
    "    plt.plot(sat_act[(sat_act['state'] == state)]['year'],\n",
    "         sat_act[(sat_act['state'] == state)]['act_participation'],\n",
    "         label = state,\n",
    "         marker = 'o')\n",
    "    \n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title(\"Participation Rate for States with 100% Participation for ACT\", fontsize = 24)\n",
    "plt.ylabel(\"Participation Rate\", fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 4: Amongst the 5 states with more than 50% participation for both tests, Florida and Gerogia are  currently not mandated to take either test. \n",
    "* From 2017-2019, Hawaii, North Carolina and South Carolina, which are mandated to take ACT, had more than 80% participation for ACT and about 50-60% participation for SAT.\n",
    "* For Florida and Gerogia, the participation rates are comparable between SAT and ACT but inversely related (e.g. Georgia's participation increased from 60% to 70% for SAT while decreased from 55% to 50% for ACT from 2017-2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any states show have >50% participation on both tests each year?\n",
    "sat_act[(sat_act[\"sat_participation\"] > 0.5) & (sat_act[\"act_participation\"] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the size of the figure.\n",
    "plt.figure(figsize = (16, 9))\n",
    "\n",
    "# Create line plot of participation rate for SAT over time for states with >50% participation for both tests\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title('Participation Rate for States with >50% Participation for SAT')\n",
    "\n",
    "for state in [\"Florida\", \"Georgia\", \"Hawaii\", \"North Carolina\", \"South Carolina\"]:\n",
    "                     \n",
    "    ax1.plot(sat_act[sat_act['state'] == state]['year'],\n",
    "         sat_act[sat_act['state'] == state]['sat_participation'],\n",
    "         label = state,\n",
    "         marker = 'o')\n",
    "    \n",
    "# Create line plot of participation rate for ACT over time for states with >50% participation for both tests\n",
    "ax2 = plt.subplot(1, 2, 2, sharex = ax1)\n",
    "ax2.set_title('Participation Rate for States with >50% Participation for ACT')\n",
    "\n",
    "for state in [\"Florida\", \"Georgia\", \"Hawaii\", \"North Carolina\", \"South Carolina\"]:\n",
    "    ax2.plot(sat_act[sat_act['state'] == state]['year'],\n",
    "         sat_act[sat_act['state'] == state]['act_participation'],\n",
    "         label = state,\n",
    "         marker = 'o')\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel(\"Participation Rate\", fontsize = 12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 5: SAT participation rate is strongly negatively correlated with its score, and with ACT participation rate.\n",
    "* This is likely due to statewide requirements. When students do not self select and take test as part of a requirement and only option, their scores tend to be lower. In contrast, students would voluntarily choose the test which they believe they would score higher on.\n",
    "* Preference for one standardized test over another tends to be largely geographical in nature. Thus, states with high SAT participation tends to have lower ACT participation, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise correlation \n",
    "\n",
    "# Establish size of figure.\n",
    "plt.figure(figsize = (16,9))\n",
    "\n",
    "# Get correlation of variables.\n",
    "corr = sat_act.corr()\n",
    "\n",
    "# Set up mask to be \"True\" in the upper triangle.\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot our correlation heatmap, while masking the upper triangle to be white.\n",
    "with sns.axes_style(\"white\"):\n",
    "    plot = sns.heatmap(corr, mask = mask, square = True, annot = True, vmin = -1, vmax = 1, linewidths = .5)\n",
    "    plot.set(title = \"Correlation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 6a: There are more extreme participation for SAT (100% or close to 0%). ACT is more widely adopted by states.\n",
    "* In 2017, the distribution of SAT participation was more spread out as compared to that of ACT with about one-third of the states have either 100% or close to 0% participation, as opposed to ACT which had about one-third of the states having 100% participation. Due to this, the average partipation for SAT (47%) is lower than that for ACT (61%) with a higher standard deviation (SAT: 37%; ACT: 34%).\n",
    "* The distribution of SAT participation rate in 2017 was not normally distributed as it does not have a symetrically bell-curved shape and has more than one mode with heavy mass distributed at the extreme ends instead of centre (i.e. about one-third of the states have either 100% or close to 0% participation)\n",
    "* While the distribution of the partipation rate was not normal, as the sample size of 51 is large, by Central Limit Theorem, the sample mean (i.e. the average partipation for SAT) follows a normal distribution, and we can use that to draw conclusion about the mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish figure size.\n",
    "plt.figure(figsize = (16,9))\n",
    "\n",
    "# Taking a snapshot of 2017 distribution of participation rate for SAT\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.set_title('Participation Rate for SAT in 2018')\n",
    "ax1.hist(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['sat_participation'], bins = 50)\n",
    "ax1.vlines(x = np.mean(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['sat_participation']), ymin = 0, ymax = 8, color = 'orange');\n",
    "\n",
    "# Taking a snapshot of 2017 distribution of participation rate for ACT\n",
    "ax2 = plt.subplot(2, 1, 2, sharex=ax1)\n",
    "ax2.set_title('Participation Rate for ACT in 2018')\n",
    "ax2.hist(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['act_participation'], bins = 50)\n",
    "ax2.vlines(x = np.mean(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['act_participation']), ymin = 0, ymax = 18, color = 'orange');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding 6b: Median participation rate for SAT was relatively low, comparing to ACT, suggesting that there is room for improvement.\n",
    "* The median participation rate for SAT was about 55%, lower than that for ACT which was about 65%, in 2018. \n",
    "* The spread in terms of interquartile range was about the same for both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(18, 10))\n",
    "\n",
    "fig.suptitle('Participation Rate in 2018')\n",
    "\n",
    "sns.boxplot(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['sat_participation'], ax=axes[0]).set(xlabel='SAT')\n",
    "\n",
    "sns.boxplot(sat_act[sat_act['year'] == pd.to_datetime(\"2018-01-01\")]['act_participation'], ax=axes[1]).set(xlabel='ACT');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 7a: SAT and ACT participation are negatively correlated to their respective scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the size of the figure.\n",
    "plt.figure(figsize = (16, 9))\n",
    "\n",
    "# Create scatterplot of high prices versus volume.\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.scatter(sat_act['sat_participation'],\n",
    "            sat_act['sat_total'],)\n",
    "\n",
    "ax1.set_title(\"SAT Participation versus SAT Total Score\", fontsize = 20)\n",
    "ax1.set_ylabel(\"SAT Total Score\", fontsize = 15)\n",
    "ax1.set_xlabel(\"SAT Participation\", fontsize = 15)\n",
    "\n",
    "\n",
    "# Create scatterplot of high prices versus volume.\n",
    "ax2 = plt.subplot(1, 2, 2, sharex=ax1)\n",
    "ax2.scatter(sat_act['act_participation'],\n",
    "            sat_act['act_composite'],)\n",
    "\n",
    "ax2.set_title(\"ACT Participation versus ACT Composite Score\", fontsize = 20)\n",
    "ax2.set_ylabel(\"ACT Composite Score\", fontsize = 15)\n",
    "ax2.set_xlabel(\"ACT Participation\", fontsize = 15);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation 7b: Excluding states with mandatory ACT and SAT, and removing outlier SAT scores (extreme high or low scores) amongst the rest of the states, we recommend focusing on 9 states to increase SAT participation rate (see Recommendations).\n",
    "* Since it is difficult to increase SAT participation for states which have adopted ACT, and states which have adopted SAT are likely to continue having high participation, we excluded states with mandatory tests, and further study the relationship between participation and scores amongst the rest of the states, before providing recommendations on the states to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter for year 2018 and states without mandatory ACT or SAT\n",
    "sat_state_w_full_participation = sat_act.loc[sat_act['state'].isin([\"Connecticut\", \"Delaware\", \"District of Columbia\", \"Michigan\", \"Colorado\", \"Idaho\", \"Illinois\", \"Rhode Island\", \"Maine\", \"New Hampshire\"])]['state'].unique()\n",
    "sat_state_w_lowest_participation = sat_act.loc[sat_act['state'].isin([\"North Dakota\", \"Mississippi\", \"Iowa\"])]['state'].unique()\n",
    "act_state_w_full_participation = sat_act.loc[sat_act['state'].isin([\"Alabama\", \"Arkansas\", \"Colorado\", \"Kentucky\", \"Louisiana\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nevada\", \"North Carolina\", \"Oklahoma\", \"South Carolina\", \"Tennessee\", \"Utah\", \"Wisconsin\", \"Wyoming\", \"Nebraska\", \"Ohio\"])][\"state\"].unique()\n",
    "act_state_w_lowest_participation = sat_act.loc[sat_act['state'].isin([\"Maine\"])][\"state\"].unique()\n",
    "\n",
    "filter_no_full_participation_for_either_test_2018 = (~(sat_act['state'].isin(act_state_w_full_participation) | sat_act['state'].isin(sat_state_w_full_participation))) & (sat_act[\"year\"] == pd.to_datetime(\"2018-01-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_participation_vs_sat_act_score(filter):\n",
    "    \"\"\"Input filter for state and output scatterplot of SAT and ACT participation vs their respective score\"\"\"\n",
    "    # Establish the size of the figure.\n",
    "    plt.figure(figsize = (16, 9))\n",
    "\n",
    "    # Unique category labels: 'D', 'F', 'G', ...\n",
    "    #color_labels = sat_act[filter][\"state\"].unique()\n",
    "\n",
    "    # List of RGB triplets\n",
    "    #rgb_values = sns.color_palette(\"Set2\", len(sat_act[filter][\"state\"].unique()))\n",
    "\n",
    "    # Map label to RGB\n",
    "    #color_map = dict(zip(color_labels, rgb_values))\n",
    "\n",
    "    # Create scatterplot of high prices versus volume.\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1.scatter(sat_act[filter]['sat_participation'],\n",
    "                sat_act[filter]['sat_total'],\n",
    "                #c=sat_act[filter][\"state\"].map(color_map),\n",
    "               )\n",
    "\n",
    "    ax1.set_title(\"SAT Participation versus SAT Total Score\")\n",
    "    ax1.set_ylabel(\"SAT Total Score\", fontsize = 20)\n",
    "    ax1.set_xlabel(\"SAT Participation\", fontsize = 20)\n",
    "\n",
    "\n",
    "    # Create scatterplot of high prices versus volume.\n",
    "    ax2 = plt.subplot(1, 2, 2, sharex=ax1)\n",
    "    ax2.scatter(sat_act[filter]['act_participation'],\n",
    "                sat_act[filter]['act_composite'],\n",
    "                #c=sat_act[filter][\"state\"].map(color_map),\n",
    "               )\n",
    "\n",
    "    ax2.set_title(\"ACT Participation versus ACT Composite Score\")\n",
    "    ax2.set_ylabel(\"ACT Composite Score\", fontsize = 20)\n",
    "    ax2.set_xlabel(\"ACT Participation\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_participation_vs_sat_act_score(filter_no_full_participation_for_either_test_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(18, 10))\n",
    "\n",
    "fig.suptitle('Overall Score in 2018')\n",
    "\n",
    "sns.boxplot(sat_act[filter_no_full_participation_for_either_test_2018]['sat_total'], ax=axes[0]).set(xlabel='SAT')\n",
    "\n",
    "sns.boxplot(sat_act[filter_no_full_participation_for_either_test_2018]['act_composite'], ax=axes[1]).set(xlabel='ACT');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outlier states for SAT score - North Dakota, Iowa, Kansas, South Dakota, West Virginia - and remove them from the recommendation\n",
    "sat_act.loc[filter_no_full_participation_for_either_test_2018, [\"state\", \"sat_total\"]].sort_values(\"sat_total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on the 5 states to the filter \n",
    "filter_no_full_participation_for_either_test_and_outliers_2018 = (~(sat_act['state'].isin(act_state_w_full_participation) | sat_act['state'].isin(sat_state_w_full_participation) | sat_act['state'].isin([\"North Dakota\", \"Iowa\", \"Kansas\", \"South Dakota\", \"West Virginia\"]))) & (sat_act[\"year\"] == pd.to_datetime(\"2018-01-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_subset = sat_act.loc[filter_no_full_participation_for_either_test_and_outliers_2018,['state','sat_participation','sat_total']]\n",
    "act_subset = sat_act.loc[filter_no_full_participation_for_either_test_and_outliers_2018,['state','act_participation','act_composite']]\n",
    "#act_x = sat_act[filter_no_full_participation_for_either_test_and_outliers_2018]['act_participation']\n",
    "#act_y = sat_act[filter_no_full_participation_for_either_test_and_outliers_2018]['act_composite']\n",
    "#state_label = sat_act[filter_no_full_participation_for_either_test_and_outliers_2018]['state']\n",
    "\n",
    "plt.figure(figsize = (25, 15))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(sat_subset['sat_participation'], sat_subset['sat_total'], 'o')\n",
    "m, b = np.polyfit(sat_subset['sat_participation'], sat_subset['sat_total'], 1)\n",
    "ax1.plot(sat_subset['sat_participation'], m*sat_subset['sat_participation'] + b)\n",
    "\n",
    "for state in sat_subset['state'].index:\n",
    "     ax1.text(sat_subset['sat_participation'][state],y=sat_subset['sat_total'][state],s=sat_subset['state'][state], \n",
    "          fontdict=dict(color='red',size=15),\n",
    "          bbox=dict(facecolor='yellow',alpha=0.3))\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(act_subset['act_participation'], act_subset['act_composite'], 'o')\n",
    "m, b = np.polyfit(act_subset['act_participation'], act_subset['act_composite'], 1)\n",
    "ax2.plot(act_subset['act_participation'], m*act_subset['act_participation'] + b)\n",
    "\n",
    "for state in act_subset['state'].index:\n",
    "     ax2.text(act_subset['act_participation'][state],y=act_subset['act_composite'][state],s=act_subset['state'][state], \n",
    "          fontdict=dict(color='red',size=15),\n",
    "          bbox=dict(facecolor='yellow',alpha=0.3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "* States with high SAT participation are those which made SAT mandatory while those with low participation are those which made ACT mandatory.\n",
    "* States with low participation generally had high SAT score and high participation had low score. Similarly for ACT.\n",
    "* States with 100% participation for SAT typically continue to have high participation thereafter, due to it being made mandatory. Similarly for ACT. \n",
    "* Amongst states with >50% participation for both tests, Florida and Gerogia are currently not mandated to take either test. \n",
    "* Median participation rate for SAT was relatively low (about 55%), as compared to ACT (about 65%), suggesting that there is room for improvement.\n",
    "* Since it is difficult to increase SAT participation for states which have adopted ACT, and states which have adopted SAT are likely to continue having high participation, we excluded states with mandatory tests, and recommend focusing resources on the other states to improve SAT participation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommmendations: \n",
    "* Excluding states with mandatory ACT and SAT, we recommend focusing resoures on the following states to improve SAT participation:\n",
    "    * *Focus first*: States with relatively high SAT score, as compared to ACT score). As their relative overall score is higher for SAT, we can use this as a basis to propose to the Boards of Education in these states to make SAT mandatory in their states:\n",
    "        - Arizona\n",
    "        - Alaska\n",
    "        - Oregon\n",
    "        - Florida\n",
    "    * *Focus next*: States with relatively high participation rate, as compared to ACT participation:\n",
    "        - Vermont\n",
    "        - Virginia\n",
    "        - Massachusetts\n",
    "        - New Jersey\n",
    "        - Pennsylvania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
